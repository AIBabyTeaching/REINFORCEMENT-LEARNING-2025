# Lab 07 — Double Q-Learning

    ## Learning Objectives
    - Reduce overestimation bias
- Compare against vanilla Q-learning
- Plot stochastic reward behaviour

    ## Reading List
    - Hasselt (2010)
- Deep RL Bootcamp Lecture 3
- FrozenLake documentation

    ## Tasks
    1. Execute the notebook `07_double_q_learning_frozenlake.ipynb` start-to-finish using the provided kernel.
    2. Complete the inline questions and implement code where indicated.
    3. Save generated plots to `assets/figures/` (automated cells already handle this).
    4. Submit a short reflection covering insights, challenges, and runtime observations.

    ## Deliverables
    - Exported notebook (`.ipynb` or `.html`) with all cells executed.
    - Figures referenced in the notebook under `assets/figures/`.
    - Summary paragraph answering the lab-specific reflection prompts.

    ## Expected Runtime
    - Approximately 19 minutes on a modern laptop (i7/Ryzen, 16 GB RAM).


## Grading Rubric

- **Correctness (40%)** – unit tests and reference checks pass.
- **Clarity (20%)** – code and narrative are well explained.
- **Analysis (20%)** – figures and discussion interpret results.
- **Reproducibility (20%)** – seeds fixed, runtime within guidance.
