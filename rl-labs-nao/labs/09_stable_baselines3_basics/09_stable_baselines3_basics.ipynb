{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lab 09 \u2014 Stable-Baselines3 Quickstarts\\nTrain PPO on CartPole and A2C on LunarLander with minimal steps."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import gymnasium as gym\nfrom stable_baselines3 import PPO, A2C\nfrom stable_baselines3.common.evaluation import evaluate_policy\n\ncartpole_env = gym.make(\"CartPole-v1\")\nppo_model = PPO(\"MlpPolicy\", cartpole_env, verbose=0, n_steps=256, batch_size=64)\nppo_model.learn(total_timesteps=512)\navg_reward, _ = evaluate_policy(ppo_model, cartpole_env, n_eval_episodes=5, deterministic=True)\nprint(f\"PPO average reward: {avg_reward:.2f}\")\ncartpole_env.close()\n\nlunar_env = gym.make(\"LunarLander-v2\")\na2c_model = A2C(\"MlpPolicy\", lunar_env, verbose=0, n_steps=128)\na2c_model.learn(total_timesteps=256)\navg_reward, _ = evaluate_policy(a2c_model, lunar_env, n_eval_episodes=3, deterministic=False)\nprint(f\"A2C average reward: {avg_reward:.2f}\")\nlunar_env.close()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "RL Labs (py311)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}