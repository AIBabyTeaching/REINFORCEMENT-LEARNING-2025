# Lab 01 — Multi-Armed Bandits

    ## Learning Objectives
    - Implement ε-greedy and optimistic initialisation
- Compare with UCB action selection
- Analyse exploration vs. exploitation

    ## Reading List
    - Sutton & Barto (2018) Chapter 2
- Auer et al. (2002) - Finite-time Analysis of the Multiarmed Bandit Problem
- OpenAI Spinning Up notes on bandits

    ## Tasks
    1. Execute the notebook `01_bandits_from_scratch.ipynb` start-to-finish using the provided kernel.
    2. Complete the inline questions and implement code where indicated.
    3. Save generated plots to `assets/figures/` (automated cells already handle this).
    4. Submit a short reflection covering insights, challenges, and runtime observations.

    ## Deliverables
    - Exported notebook (`.ipynb` or `.html`) with all cells executed.
    - Figures referenced in the notebook under `assets/figures/`.
    - Summary paragraph answering the lab-specific reflection prompts.

    ## Expected Runtime
    - Approximately 12 minutes on a modern laptop (i7/Ryzen, 16 GB RAM).


## Grading Rubric

- **Correctness (40%)** – unit tests and reference checks pass.
- **Clarity (20%)** – code and narrative are well explained.
- **Analysis (20%)** – figures and discussion interpret results.
- **Reproducibility (20%)** – seeds fixed, runtime within guidance.
