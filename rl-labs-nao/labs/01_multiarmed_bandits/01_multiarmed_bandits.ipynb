{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lab 01 \u2014 Multiarmed Bandits"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import importlib.util\nimport sys\nfrom pathlib import Path\nROOT = Path(__file__).resolve().parents[2]\nif str(ROOT) not in sys.path:\n    sys.path.insert(0, str(ROOT))\n\nmodule_path = ROOT / \"labs/01_multiarmed_bandits/solutions/bandits_solution.py\"\nspec = importlib.util.spec_from_file_location(\"bandits_solution\", module_path)\nbandits = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(bandits)\nimport numpy as np\nfrom common import plotting\narms = [bandits.BanditArm(0.2), bandits.BanditArm(0.0), bandits.BanditArm(0.5), bandits.BanditArm(0.1)]\nsteps = 200\nrewards_eps, optimal_eps = bandits.run_bandit(arms, bandits.EpsilonGreedyAgent(len(arms), epsilon=0.1, optimistic=0.5), steps)\nrewards_ucb, optimal_ucb = bandits.run_bandit(arms, bandits.UCBAgent(len(arms), c=2.0), steps)\navg_reward_eps = rewards_eps.cumsum() / np.arange(1, steps + 1)\navg_reward_ucb = rewards_ucb.cumsum() / np.arange(1, steps + 1)\nplotting.multi_curve([avg_reward_eps, avg_reward_ucb], [\"\u03b5-greedy\", \"UCB\"], \"Average Reward\", \"lab01_avg_reward.png\")\nplotting.multi_curve([optimal_eps.cumsum() / np.arange(1, steps + 1), optimal_ucb.cumsum() / np.arange(1, steps + 1)], [\"\u03b5-greedy\", \"UCB\"], \"Optimal Action Rate\", \"lab01_optimal_rate.png\")"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "RL Labs (py311)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}