{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lab 03 \u2014 Dynamic Programming Pi Vi"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import importlib.util\nimport sys\nfrom pathlib import Path\nROOT = Path(__file__).resolve().parents[2]\nif str(ROOT) not in sys.path:\n    sys.path.insert(0, str(ROOT))\n\npi_path = ROOT / \"labs/03_dynamic_programming_pi_vi/solutions/policy_iteration.py\"\nvi_path = ROOT / \"labs/03_dynamic_programming_pi_vi/solutions/value_iteration.py\"\npi_spec = importlib.util.spec_from_file_location(\"policy_iteration\", pi_path)\npi = importlib.util.module_from_spec(pi_spec)\npi_spec.loader.exec_module(pi)\nvi_spec = importlib.util.spec_from_file_location(\"value_iteration\", vi_path)\nvi = importlib.util.module_from_spec(vi_spec)\nvi_spec.loader.exec_module(vi)\nfrom common import mdp, plotting\nworld = mdp.Gridworld(width=4, height=4, terminal_states=[(0,0),(3,3)], step_reward=-1.0)\nvalues_pi, policy_pi = pi.policy_iteration(world, gamma=1.0)\nvalues_vi, policy_vi = vi.value_iteration(world, gamma=1.0)\nplotting.save_heatmap(values_pi.reshape(4,4), \"Policy Iteration Values\", \"lab03_policy_iteration.png\", annotations=True)\nplotting.save_heatmap(values_vi.reshape(4,4), \"Value Iteration Values\", \"lab03_value_iteration.png\", annotations=True)\nvalues_pi.reshape(4,4)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "RL Labs (py311)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}