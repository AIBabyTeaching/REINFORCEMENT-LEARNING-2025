# Lab 08 — Function Approximation & DQN

    ## Learning Objectives
    - Explore linear vs. neural value approximators
- Implement target networks and replay
- Monitor loss stability

    ## Reading List
    - Mnih et al. (2015)
- Stable-Baselines3 DQN docs
- PyTorch quickstart

    ## Tasks
    1. Execute the notebook `08_dqn_linear_vs_nn.ipynb` start-to-finish using the provided kernel.
    2. Complete the inline questions and implement code where indicated.
    3. Save generated plots to `assets/figures/` (automated cells already handle this).
    4. Submit a short reflection covering insights, challenges, and runtime observations.

    ## Deliverables
    - Exported notebook (`.ipynb` or `.html`) with all cells executed.
    - Figures referenced in the notebook under `assets/figures/`.
    - Summary paragraph answering the lab-specific reflection prompts.

    ## Expected Runtime
    - Approximately 22 minutes on a modern laptop (i7/Ryzen, 16 GB RAM).


## Grading Rubric

- **Correctness (40%)** – unit tests and reference checks pass.
- **Clarity (20%)** – code and narrative are well explained.
- **Analysis (20%)** – figures and discussion interpret results.
- **Reproducibility (20%)** – seeds fixed, runtime within guidance.
